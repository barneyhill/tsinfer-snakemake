{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch VCF and index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import sgkit\n",
    "! mkdir -p data\n",
    "! test ! -e data/chr22.vcf.gz && wget -O data/chr22.vcf.gz http://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000G_2504_high_coverage/working/20201028_3202_phased/CCDG_14151_B01_GRM_WGS_2020-08-05_chr22.filtered.shapeit2-duohmm-phased.vcf.gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "! test ! -e data/chr22.vcf.gz.tbi && tabix -f -p vcf data/chr22.vcf.gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fetch ancestral alleles and index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will not apply HSTS. The HSTS database must be a regular and non-world-writable file.\r\n",
      "ERROR: could not open HSTS store at '/home/benj/.wget-hsts'. HSTS will be disabled.\r\n",
      "--2023-01-19 00:40:39--  ftp://ftp.ensembl.org/pub/release-100/fasta/ancestral_alleles/homo_sapiens_ancestor_GRCh38.tar.gz\r\n",
      "           => ‘data/ancestral_alleles.tar.gz’\r\n",
      "Resolving ftp.ensembl.org (ftp.ensembl.org)... 193.62.193.139\r\n",
      "Connecting to ftp.ensembl.org (ftp.ensembl.org)|193.62.193.139|:21... connected.\r\n",
      "Logging in as anonymous ... Logged in!\r\n",
      "==> SYST ... done.    ==> PWD ... done.\r\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/release-100/fasta/ancestral_alleles ... done.\r\n",
      "==> SIZE homo_sapiens_ancestor_GRCh38.tar.gz ... 852605016\r\n",
      "==> PASV ... done.    ==> RETR homo_sapiens_ancestor_GRCh38.tar.gz ... done.\r\n",
      "Length: 852605016 (813M) (unauthoritative)\r\n",
      "\r\n",
      "homo_sapiens_ancest 100%[===================>] 813.11M  5.30MB/s    in 2m 33s  \r\n",
      "\r\n",
      "2023-01-19 00:43:12 (5.33 MB/s) - ‘data/ancestral_alleles.tar.gz’ saved [852605016]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! test ! -e data/ancestral_alleles.tar.gz && wget -O data/ancestral_alleles.tar.gz  ftp://ftp.ensembl.org/pub/release-100/fasta/ancestral_alleles/homo_sapiens_ancestor_GRCh38.tar.gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "! cd data && tar -xzf ancestral_alleles.tar.gz"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "! samtools faidx data/homo_sapiens_ancestor_GRCh38/homo_sapiens_ancestor_22.fa"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert VCF to an sgkit dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.2 s, sys: 393 ms, total: 14.6 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sgkit as sg\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "from sgkit.io.vcf import vcf_to_zarr"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 40s, sys: 22.8 s, total: 8min 3s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vcf_to_zarr(\"data/chr22.vcf.gz\", \"data/chr22.zarr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load ancestral states from fasta and save to dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seen states:\n",
      "- 51535\n",
      ". 141300\n",
      "A 130150\n",
      "C 252721\n",
      "G 236782\n",
      "N 8216\n",
      "T 127890\n",
      "a 21735\n",
      "c 40884\n",
      "g 37531\n",
      "t 21657\n"
     ]
    }
   ],
   "source": [
    "import pysam\n",
    "import sys\n",
    "fasta = pysam.FastaFile(\"data/homo_sapiens_ancestor_GRCh38/homo_sapiens_ancestor_22.fa\")\n",
    "# NB! We put in an extra character at the start to convert to 1 based coords.\n",
    "codec = 'utf-32-le' if sys.byteorder == 'little' else 'utf-32-be'\n",
    "ancestral_sequence = \"X\" + fasta.fetch(reference=fasta.references[0])\n",
    "ancestral_sequence = np.frombuffer(bytearray(ancestral_sequence,codec), dtype=\"U1\")\n",
    "# From the ancestral states README:\n",
    "# The convention for the sequence is:\n",
    "#    ACTG : high-confidence call, ancestral state supported by other 2 sequences\n",
    "#    actg : low-confidence call, ancestral state supported by one sequence only\n",
    "#    N    : failure, the ancestral state is not supported by any other sequence\n",
    "#    -    : the extant species contains an insertion at this position\n",
    "#    .    : no coverage in the alignment\n",
    "ds = sg.load_dataset(\"data/chr22.zarr\")\n",
    "ancestral_states = ancestral_sequence[ds['variant_position'].values]\n",
    "ancestral_states = xr.DataArray(data=ancestral_states, dims=[\"variants\"], name=\"variant_ancestral_state\")\n",
    "print(\"Seen states:\")\n",
    "for val, count in zip(*np.unique(ancestral_states, return_counts=True)):\n",
    "    print(val, count)\n",
    "ds.update({\"variant_ancestral_state\": ancestral_states})\n",
    "sg.save_dataset(ds.drop_vars(set(ds.data_vars) - {\"variant_ancestral_state\"}), \"data/chr22.zarr\", mode=\"a\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a mask of sites that have bad ancestral states"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201051 sites masked out for bad ancestral state\n"
     ]
    }
   ],
   "source": [
    "ds = sg.load_dataset(\"data/chr22.zarr\")\n",
    "wanted_variants = da.logical_and(ds['variant_ancestral_state'] != '-',\n",
    "                     da.logical_and(ds['variant_ancestral_state'] != '.', ds['variant_ancestral_state'] != 'N'))\n",
    "wanted_variants = wanted_variants.chunk((10000,))\n",
    "ds.update({\"variant_bad_ancestral_mask\": xr.DataArray(data=wanted_variants, dims=[\"variants\"], name=\"variant_bad_ancestral_mask\")})\n",
    "sg.save_dataset(ds.drop_vars(set(ds.data_vars) - {\"variant_bad_ancestral_mask\"}), \"data/chr22.zarr\", mode=\"a\")\n",
    "print(f\"{da.sum(~wanted_variants).compute()} sites masked out for bad ancestral state\")\n",
    "assert set(np.unique(ds['variant_ancestral_state'][wanted_variants])) == {'A', 'C', 'G', 'T', 'a', 'c', 'g', 't'}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a mask of duplicate positions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99504 sites masked out for duplicate position\n"
     ]
    }
   ],
   "source": [
    "ds = sg.load_dataset(\"data/chr22.zarr\")\n",
    "pos = ds['variant_position']\n",
    "pos_shift_left = da.full_like(pos,-1)\n",
    "pos_shift_left[0:-1] = pos[1:]\n",
    "pos_shift_right = da.full_like(pos,-1)\n",
    "pos_shift_right[1:] = pos[:-1]\n",
    "wanted_variants = da.logical_and(pos != pos_shift_left, pos != pos_shift_right)\n",
    "ds.update({\"variant_duplicate_position_mask\": xr.DataArray(data=wanted_variants, dims=[\"variants\"], name=\"variant_duplicate_position_mask\")})\n",
    "sg.save_dataset(ds.drop_vars(set(ds.data_vars) - {\"variant_duplicate_position_mask\"}), \"data/chr22.zarr\", mode=\"a\")\n",
    "print(f\"{da.sum(~wanted_variants).compute()} sites masked out for duplicate position\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the combined mask"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'variant_duplicate_position_mask' (variants: 1070401)>\n",
      "dask.array<open_dataset-b70e6d3b582f66d0cb6ee07e93ae7bd5variant_duplicate_position_mask, shape=(1070401,), dtype=bool, chunksize=(10000,), chunktype=numpy.ndarray>\n",
      "Dimensions without coordinates: variants <xarray.DataArray 'variant_bad_ancestral_mask' (variants: 1070401)>\n",
      "dask.array<open_dataset-b70e6d3b582f66d0cb6ee07e93ae7bd5variant_bad_ancestral_mask, shape=(1070401,), dtype=bool, chunksize=(10000,), chunktype=numpy.ndarray>\n",
      "Dimensions without coordinates: variants\n",
      "276599 sites masked out\n"
     ]
    }
   ],
   "source": [
    "## Create the combined mask\n",
    "ds = sg.load_dataset(\"data/chr22.zarr\")\n",
    "wanted_variants = da.logical_and(ds['variant_duplicate_position_mask'], ds['variant_bad_ancestral_mask'])\n",
    "ds.update({\"variant_mask\": xr.DataArray(data=wanted_variants, dims=[\"variants\"], name=\"variant_mask\")})\n",
    "sg.save_dataset(ds.drop_vars(set(ds.data_vars) - {\"variant_mask\"}), \"data/chr22.zarr\", mode=\"a\")\n",
    "print(f\"{da.sum(~wanted_variants).compute()} sites masked out\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "ds = sg.load_dataset(\"data/chr22.zarr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Take a subset of the samples for testing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "ename": "ContainsGroupError",
     "evalue": "path '' contains a group",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mContainsGroupError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[36], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m wanted_samples[:\u001B[38;5;241m100\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m      4\u001B[0m ds \u001B[38;5;241m=\u001B[39m ds\u001B[38;5;241m.\u001B[39msel(samples\u001B[38;5;241m=\u001B[39mwanted_samples)\n\u001B[0;32m----> 5\u001B[0m \u001B[43msg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdata/chr22.subset.zarr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/ukb/nygc1000_notebook/env/lib/python3.10/site-packages/sgkit/io/dataset.py:84\u001B[0m, in \u001B[0;36msave_dataset\u001B[0;34m(ds, store, storage_options, auto_rechunk, **kwargs)\u001B[0m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m     80\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mZarr requires uniform chunk sizes. Use the `auto_rechunk` argument to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     81\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`save_dataset` to automatically rechunk the dataset.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     82\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 84\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\n",
      "File \u001B[0;32m~/projects/ukb/nygc1000_notebook/env/lib/python3.10/site-packages/sgkit/io/dataset.py:74\u001B[0m, in \u001B[0;36msave_dataset\u001B[0;34m(ds, store, storage_options, auto_rechunk, **kwargs)\u001B[0m\n\u001B[1;32m     72\u001B[0m \u001B[38;5;66;03m# Catch unequal chunking errors to provide a more helpful error message\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 74\u001B[0m     \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_zarr\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mZarr requires uniform chunk sizes\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(\n\u001B[1;32m     77\u001B[0m         e\n\u001B[1;32m     78\u001B[0m     ) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal chunk of Zarr array must be the same size\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e):\n",
      "File \u001B[0;32m~/projects/ukb/nygc1000_notebook/env/lib/python3.10/site-packages/xarray/core/dataset.py:2091\u001B[0m, in \u001B[0;36mDataset.to_zarr\u001B[0;34m(self, store, chunk_store, mode, synchronizer, group, encoding, compute, consolidated, append_dim, region, safe_chunks, storage_options, zarr_version)\u001B[0m\n\u001B[1;32m   1974\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Write dataset contents to a zarr group.\u001B[39;00m\n\u001B[1;32m   1975\u001B[0m \n\u001B[1;32m   1976\u001B[0m \u001B[38;5;124;03mZarr chunks are determined in the following way:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2087\u001B[0m \u001B[38;5;124;03m    The I/O user guide, with more details and examples.\u001B[39;00m\n\u001B[1;32m   2088\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2089\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackends\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m to_zarr\n\u001B[0;32m-> 2091\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_zarr\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m   2092\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2093\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstore\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2094\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunk_store\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_store\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2095\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2096\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2097\u001B[0m \u001B[43m    \u001B[49m\u001B[43msynchronizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynchronizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2098\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2099\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2100\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompute\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2101\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconsolidated\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconsolidated\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2102\u001B[0m \u001B[43m    \u001B[49m\u001B[43mappend_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mappend_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2103\u001B[0m \u001B[43m    \u001B[49m\u001B[43mregion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2104\u001B[0m \u001B[43m    \u001B[49m\u001B[43msafe_chunks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_chunks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2105\u001B[0m \u001B[43m    \u001B[49m\u001B[43mzarr_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzarr_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2106\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/ukb/nygc1000_notebook/env/lib/python3.10/site-packages/xarray/backends/api.py:1628\u001B[0m, in \u001B[0;36mto_zarr\u001B[0;34m(dataset, store, chunk_store, mode, synchronizer, group, encoding, compute, consolidated, append_dim, region, safe_chunks, storage_options, zarr_version)\u001B[0m\n\u001B[1;32m   1626\u001B[0m     already_consolidated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1627\u001B[0m     consolidate_on_close \u001B[38;5;241m=\u001B[39m consolidated \u001B[38;5;129;01mor\u001B[39;00m consolidated \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1628\u001B[0m zstore \u001B[38;5;241m=\u001B[39m \u001B[43mbackends\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mZarrStore\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_group\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1629\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstore\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1630\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1631\u001B[0m \u001B[43m    \u001B[49m\u001B[43msynchronizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msynchronizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1632\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgroup\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1633\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconsolidated\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43malready_consolidated\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1634\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconsolidate_on_close\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconsolidate_on_close\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1635\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunk_store\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_mapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1636\u001B[0m \u001B[43m    \u001B[49m\u001B[43mappend_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mappend_dim\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1637\u001B[0m \u001B[43m    \u001B[49m\u001B[43mwrite_region\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1638\u001B[0m \u001B[43m    \u001B[49m\u001B[43msafe_chunks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_chunks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1639\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstacklevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# for Dataset.to_zarr()\u001B[39;49;00m\n\u001B[1;32m   1640\u001B[0m \u001B[43m    \u001B[49m\u001B[43mzarr_version\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mzarr_version\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1641\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1643\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1644\u001B[0m     _validate_datatypes_for_zarr_append(zstore, dataset)\n",
      "File \u001B[0;32m~/projects/ukb/nygc1000_notebook/env/lib/python3.10/site-packages/xarray/backends/zarr.py:420\u001B[0m, in \u001B[0;36mZarrStore.open_group\u001B[0;34m(cls, store, mode, synchronizer, group, consolidated, consolidate_on_close, chunk_store, storage_options, append_dim, write_region, safe_chunks, stacklevel, zarr_version)\u001B[0m\n\u001B[1;32m    418\u001B[0m     zarr_group \u001B[38;5;241m=\u001B[39m zarr\u001B[38;5;241m.\u001B[39mopen_consolidated(store, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mopen_kwargs)\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 420\u001B[0m     zarr_group \u001B[38;5;241m=\u001B[39m \u001B[43mzarr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen_group\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mopen_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mcls\u001B[39m(\n\u001B[1;32m    422\u001B[0m     zarr_group,\n\u001B[1;32m    423\u001B[0m     mode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    427\u001B[0m     safe_chunks,\n\u001B[1;32m    428\u001B[0m )\n",
      "File \u001B[0;32m~/projects/ukb/nygc1000_notebook/env/lib/python3.10/site-packages/zarr/hierarchy.py:1389\u001B[0m, in \u001B[0;36mopen_group\u001B[0;34m(store, mode, cache_attrs, synchronizer, path, chunk_store, storage_options, zarr_version, meta_array)\u001B[0m\n\u001B[1;32m   1387\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ContainsArrayError(path)\n\u001B[1;32m   1388\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m contains_group(store, path\u001B[38;5;241m=\u001B[39mpath):\n\u001B[0;32m-> 1389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ContainsGroupError(path)\n\u001B[1;32m   1390\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1391\u001B[0m     init_group(store, path\u001B[38;5;241m=\u001B[39mpath, chunk_store\u001B[38;5;241m=\u001B[39mchunk_store)\n",
      "\u001B[0;31mContainsGroupError\u001B[0m: path '' contains a group"
     ]
    }
   ],
   "source": [
    "ds = sg.load_dataset(\"data/chr22.zarr\")\n",
    "wanted_samples = np.zeros((ds.sizes['samples'],), dtype=bool)\n",
    "wanted_samples[:100] = True\n",
    "ds = ds.sel(samples=wanted_samples)\n",
    "sg.save_dataset(ds, \"data/chr22.subset.zarr\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ga-add   (1/6)100%|██████████| 971k/971k [00:22, 42.8kit/s] \n",
      "ga-gen   (2/6)100%|██████████| 77.0k/77.0k [06:16, 204it/s]\n",
      "ma-match (3/6)100%|█████████▉| 77.0k/77.0k [02:33, 408it/s]\n",
      "ms-muts  (4/6)  0%|          | 0.00/155k [00:00, ?it/s]\u001B[A\n",
      "ms-muts  (4/6)  0%|          | 1.00/155k [00:00, 2.28it/s]\u001B[A\n",
      "ms-muts  (4/6)  3%|▎         | 5.18k/155k [00:00, 9.69kit/s]\u001B[A\n",
      "ms-muts  (4/6)  7%|▋         | 10.7k/155k [00:00, 17.0kit/s]\u001B[A\n",
      "ms-muts  (4/6) 11%|█         | 16.4k/155k [00:00, 22.5kit/s]\u001B[A\n",
      "ms-muts  (4/6) 14%|█▍        | 22.3k/155k [00:00, 27.0kit/s]\u001B[A\n",
      "ms-muts  (4/6) 18%|█▊        | 28.1k/155k [00:00, 30.3kit/s]\u001B[A\n",
      "ms-muts  (4/6) 22%|██▏       | 34.2k/155k [00:01, 33.5kit/s]\u001B[A\n",
      "ms-muts  (4/6) 26%|██▌       | 40.5k/155k [00:01, 36.2kit/s]\u001B[A\n",
      "ms-muts  (4/6) 30%|███       | 46.6k/155k [00:01, 38.3kit/s]\u001B[A\n",
      "ms-muts  (4/6) 34%|███▍      | 52.8k/155k [00:01, 40.1kit/s]\u001B[A\n",
      "ms-muts  (4/6) 38%|███▊      | 59.0k/155k [00:01, 41.8kit/s]\u001B[A\n",
      "ms-muts  (4/6) 42%|████▏     | 65.3k/155k [00:01, 43.2kit/s]\u001B[A\n",
      "ms-muts  (4/6) 46%|████▌     | 71.4k/155k [00:01, 44.4kit/s]\u001B[A\n",
      "ms-muts  (4/6) 50%|█████     | 77.7k/155k [00:01, 45.5kit/s]\u001B[A\n",
      "ms-muts  (4/6) 54%|█████▍    | 83.9k/155k [00:01, 46.5kit/s]\u001B[A\n",
      "ms-muts  (4/6) 58%|█████▊    | 90.2k/155k [00:01, 47.4kit/s]\u001B[A\n",
      "ms-muts  (4/6) 62%|██████▏   | 96.5k/155k [00:02, 48.3kit/s]\u001B[A\n",
      "ms-muts  (4/6) 66%|██████▌   | 103k/155k [00:02, 48.9kit/s] \u001B[A\n",
      "ms-muts  (4/6) 70%|███████   | 109k/155k [00:02, 49.6kit/s]\u001B[A\n",
      "ms-muts  (4/6) 74%|███████▍  | 115k/155k [00:02, 50.3kit/s]\u001B[A\n",
      "ms-muts  (4/6) 79%|███████▊  | 122k/155k [00:02, 51.0kit/s]\u001B[A\n",
      "ms-muts  (4/6) 83%|████████▎ | 128k/155k [00:02, 51.5kit/s]\u001B[A\n",
      "ms-muts  (4/6) 87%|████████▋ | 134k/155k [00:02, 52.0kit/s]\u001B[A\n",
      "ms-muts  (4/6) 91%|█████████ | 141k/155k [00:02, 52.4kit/s]\u001B[A\n",
      "ms-muts  (4/6) 95%|█████████▍| 147k/155k [00:02, 52.9kit/s]\u001B[A\n",
      "ms-muts  (4/6)100%|██████████| 155k/155k [00:02, 51.9kit/s]\u001B[A\n",
      "ma-match (3/6)100%|█████████▉| 77.0k/77.0k [02:37, 490it/s]\n",
      "ms-match (5/6)100%|██████████| 200/200 [00:16, 11.9it/s] \n",
      "ms-paths (6/6)100%|██████████| 200/200 [00:00, 329it/s] \n",
      "ms-muts  (7/6)100%|██████████| 155k/155k [00:06, 25.8kit/s] \n",
      "ms-xsites (8/6)100%|██████████| 816k/816k [00:48, 16.9kit/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min 21s, sys: 10.8 s, total: 19min 32s\n",
      "Wall time: 10min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import tsinfer\n",
    "sampledata = tsinfer.SgkitSampleData(\"data/chr22.subset.zarr\")\n",
    "inf_ts = tsinfer.infer(sampledata, num_threads=4, progress_monitor=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "970897"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_ts.num_sites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<tskit.trees.TreeSequence at 0x7fbca96e51b0>",
      "text/html": "\n            <div>\n              <style>\n                .tskit-table thead tr th {text-align: left;padding: 0.5em 0.5em;}\n                .tskit-table tbody tr td {padding: 0.5em 0.5em;}\n                .tskit-table tbody tr td:first-of-type {text-align: left;}\n                .tskit-details-label {vertical-align: top; padding-right:5px;}\n                .tskit-table-set {display: inline-flex;flex-wrap: wrap;margin: -12px 0 0 -12px;width: calc(100% + 12px);}\n                .tskit-table-set-table {margin: 12px 0 0 12px;}\n                details {display: inline-block;}\n                summary {cursor: pointer; outline: 0; display: list-item;}\n              </style>\n              <div class=\"tskit-table-set\">\n                <div class=\"tskit-table-set-table\">\n                  <table class=\"tskit-table\">\n                    <thead>\n                      <tr>\n                        <th style=\"padding:0;line-height:21px;\">\n                          <img style=\"height: 32px;display: inline-block;padding: 3px 5px 3px 0;\" src=\"https://raw.githubusercontent.com/tskit-dev/administrative/main/tskit_logo.svg\"/>\n                          <a target=\"_blank\" href=\"https://tskit.dev/tskit/docs/latest/python-api.html#the-treesequence-class\"> Tree Sequence </a>\n                        </th>\n                      </tr>\n                    </thead>\n                    <tbody>\n                      <tr><td>Trees</td><td>81252</td></tr>\n                      <tr><td>Sequence Length</td><td>50807930.0</td></tr>\n                      <tr><td>Time Units</td><td>uncalibrated</td></tr>\n                      <tr><td>Sample Nodes</td><td>200</td></tr>\n                      <tr><td>Total Size</td><td>79.9 MiB</td></tr>\n                      <tr>\n                        <td>Metadata</td><td style=\"text-align: left;\">No Metadata</td></tr>\n                    </tbody>\n                  </table>\n                </div>\n                <div class=\"tskit-table-set-table\">\n                  <table class=\"tskit-table\">\n                    <thead>\n                      <tr>\n                        <th style=\"line-height:21px;\">Table</th>\n                        <th>Rows</th>\n                        <th>Size</th>\n                        <th>Has Metadata</th>\n                      </tr>\n                    </thead>\n                    <tbody>\n                    \n                  <tr>\n                    <td>Edges</td>\n                      <td>544403</td>\n                      <td>16.6 MiB</td>\n                      <td style=\"text-align: center;\">\n                        \n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Individuals</td>\n                      <td>100</td>\n                      <td>5.2 KiB</td>\n                      <td style=\"text-align: center;\">\n                        ✅\n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Migrations</td>\n                      <td>0</td>\n                      <td>8 Bytes</td>\n                      <td style=\"text-align: center;\">\n                        \n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Mutations</td>\n                      <td>196684</td>\n                      <td>7.0 MiB</td>\n                      <td style=\"text-align: center;\">\n                        \n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Nodes</td>\n                      <td>109304</td>\n                      <td>5.4 MiB</td>\n                      <td style=\"text-align: center;\">\n                        ✅\n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Populations</td>\n                      <td>0</td>\n                      <td>24 Bytes</td>\n                      <td style=\"text-align: center;\">\n                        \n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Provenances</td>\n                      <td>1</td>\n                      <td>579 Bytes</td>\n                      <td style=\"text-align: center;\">\n                        \n                      </td>\n                    </tr>\n                \n                  <tr>\n                    <td>Sites</td>\n                      <td>970897</td>\n                      <td>46.8 MiB</td>\n                      <td style=\"text-align: center;\">\n                        ✅\n                      </td>\n                    </tr>\n                \n                    </tbody>\n                  </table>\n                </div>\n              </div>\n            </div>\n            "
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_ts"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
